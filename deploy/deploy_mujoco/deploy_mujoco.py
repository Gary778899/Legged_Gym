import time

import mujoco.viewer
import mujoco
import numpy as np
from legged_gym import LEGGED_GYM_ROOT_DIR
import torch
import yaml


def get_gravity_orientation(quaternion):
    qw = quaternion[0]
    qx = quaternion[1]
    qy = quaternion[2]
    qz = quaternion[3]

    gravity_orientation = np.zeros(3)

    gravity_orientation[0] = 2 * (-qz * qx + qw * qy)
    gravity_orientation[1] = -2 * (qz * qy + qw * qx)
    gravity_orientation[2] = 1 - 2 * (qw * qw + qz * qz)

    return gravity_orientation


def pd_control(target_q, q, kp, target_dq, dq, kd):
    """Calculates torques from position commands"""
    return (target_q - q) * kp + (target_dq - dq) * kd


if __name__ == "__main__":
    # get config file name from command line
    import argparse
    import os

    parser = argparse.ArgumentParser()
    parser.add_argument("config_file", type=str, help="config file name in the config folder")
    parser.add_argument("--record", action="store_true", help="Record video from the track camera")
    parser.add_argument("--camera", type=str, default="track", help="Camera name to use for recording")
    parser.add_argument("--output_file", type=str, default="recorded_video.mp4", help="Output video file (default: recorded_video.mp4)")
    parser.add_argument("--video_width", type=int, default=1920, help="Video width for recording (default: 1920)")
    parser.add_argument("--video_height", type=int, default=1080, help="Video height for recording (default: 1080)")
    parser.add_argument("--record_fps", type=int, default=30, help="Video FPS - records every Nth frame to match this (default: 30)")
    args = parser.parse_args()
    config_file = args.config_file
    with open(f"{LEGGED_GYM_ROOT_DIR}/deploy/deploy_mujoco/configs/{config_file}", "r") as f:
        config = yaml.load(f, Loader=yaml.FullLoader)
        policy_path = config["policy_path"].replace("{LEGGED_GYM_ROOT_DIR}", LEGGED_GYM_ROOT_DIR)
        xml_path = config["xml_path"].replace("{LEGGED_GYM_ROOT_DIR}", LEGGED_GYM_ROOT_DIR)

        simulation_duration = config["simulation_duration"]
        simulation_dt = config["simulation_dt"]
        control_decimation = config["control_decimation"]

        kps = np.array(config["kps"], dtype=np.float32)
        kds = np.array(config["kds"], dtype=np.float32)

        default_angles = np.array(config["default_angles"], dtype=np.float32)

        ang_vel_scale = config["ang_vel_scale"]
        dof_pos_scale = config["dof_pos_scale"]
        dof_vel_scale = config["dof_vel_scale"]
        action_scale = config["action_scale"]
        cmd_scale = np.array(config["cmd_scale"], dtype=np.float32)

        num_actions = config["num_actions"]
        num_obs = config["num_obs"]
        
        cmd = np.array(config["cmd_init"], dtype=np.float32)

    # define context variables
    action = np.zeros(num_actions, dtype=np.float32)
    target_dof_pos = default_angles.copy()
    obs = np.zeros(num_obs, dtype=np.float32)

    counter = 0

    # Load robot model
    m = mujoco.MjModel.from_xml_path(xml_path)
    d = mujoco.MjData(m)
    m.opt.timestep = simulation_dt

    # load policy
    policy = torch.jit.load(policy_path)

    # Setup frame recording if enabled
    if args.record:
        # Import cv2 only when recording is needed
        try:
            import cv2
        except ImportError:
            print("Error: OpenCV (cv2) is required for video recording. Install it with: pip install opencv-python")
            exit(1)
        
        # Calculate frame skip to achieve target FPS
        # simulation_dt = 0.005, so steps_per_sec = 200
        # To get target FPS output: frame_skip = steps_per_sec / target_fps = 200 / 30 â‰ˆ 6-7
        steps_per_sec = 1.0 / simulation_dt
        frame_skip = max(1, int(steps_per_sec / args.record_fps))
        
        # The INTENDED recording FPS is based on simulation steps, not wall-clock time
        # This ensures video plays at the correct simulation speed regardless of rendering speed
        intended_fps = steps_per_sec / frame_skip
        
        # Create video writer with the INTENDED FPS (not target_fps which may not match due to rendering)
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(args.output_file, fourcc, intended_fps, (args.video_width, args.video_height))
        
        print(f"Recording video to: {args.output_file}")
        print(f"  Resolution: {args.video_width}x{args.video_height}")
        print(f"  Simulation FPS: {intended_fps:.1f} (records every {frame_skip} steps)")
        print(f"  Note: Rendering speed may vary, but playback speed will match simulation")
        
        # Get camera ID
        try:
            camera_id = mujoco.mj_name2id(m, mujoco.mjtObj.mjOBJ_CAMERA, args.camera)
        except:
            print(f"Warning: Camera '{args.camera}' not found, using default camera")
            camera_id = -1
        
        # Create offscreen renderer with specified resolution
        try:
            renderer = mujoco.Renderer(m, height=args.video_height, width=args.video_width)
        except ValueError as e:
            print(f"Error: {e}")
            print(f"\nTip: If framebuffer is still too small, you can specify lower resolution with:")
            print(f"  python deploy/deploy_mujoco/deploy_mujoco.py x2.yaml --record --video_width 640 --video_height 480")
            exit(1)
        
        frame_count = 0
    else:
        renderer = None
        camera_id = None
        frame_count = 0
        frame_skip = 1
        out = None
        intended_fps = 0

    with mujoco.viewer.launch_passive(m, d) as viewer:
        # Close the viewer automatically after simulation_duration wall-seconds.
        start = time.time()
        if args.record:
            print(f"Recording started. Max duration: {simulation_duration}s. Close viewer to stop early.")
        while viewer.is_running() and time.time() - start < simulation_duration:
            step_start = time.time()
            # Control all joints using PD controller
            tau = pd_control(target_dof_pos, d.qpos[7:7+num_actions], kps, np.zeros_like(kds), d.qvel[6:6+num_actions], kds)
            d.ctrl[:num_actions] = tau
            
            # mj_step can be replaced with code that also evaluates
            # a policy and applies a control signal before stepping the physics.
            mujoco.mj_step(m, d)

            counter += 1
            if counter % control_decimation == 0:
                # Apply control signal here.

                # Create observation - use all joints
                qj = d.qpos[7:7+num_actions]
                dqj = d.qvel[6:6+num_actions]
                quat = d.qpos[3:7]
                omega = d.qvel[3:6]

                qj = (qj - default_angles) * dof_pos_scale
                dqj = dqj * dof_vel_scale
                gravity_orientation = get_gravity_orientation(quat)
                omega = omega * ang_vel_scale

                period = 0.8
                count = counter * simulation_dt
                phase = count % period / period
                sin_phase = np.sin(2 * np.pi * phase)
                cos_phase = np.cos(2 * np.pi * phase)

                obs[:3] = omega
                obs[3:6] = gravity_orientation
                obs[6:9] = cmd * cmd_scale
                obs[9 : 9 + num_actions] = qj
                obs[9 + num_actions : 9 + 2 * num_actions] = dqj
                obs[9 + 2 * num_actions : 9 + 3 * num_actions] = action
                obs[9 + 3 * num_actions : 9 + 3 * num_actions + 2] = np.array([sin_phase, cos_phase])
                obs_tensor = torch.from_numpy(obs).unsqueeze(0)
                # policy inference
                action = policy(obs_tensor).detach().numpy().squeeze()
                # transform action to target_dof_pos
                target_dof_pos = action * action_scale + default_angles

            # Pick up changes to the physics state, apply perturbations, update options from GUI.
            viewer.sync()

            # Record frame if enabled
            if args.record and renderer is not None:
                # Record every Nth frame based on target FPS
                if counter % frame_skip == 0:
                    renderer.update_scene(d, camera=camera_id)
                    pixels = renderer.render()
                    
                    # Convert RGB to BGR for OpenCV
                    frame_bgr = cv2.cvtColor(pixels, cv2.COLOR_RGB2BGR)
                    out.write(frame_bgr)
                    frame_count += 1

            # Rudimentary time keeping, will drift relative to wall clock.
            time_until_next_step = m.opt.timestep - (time.time() - step_start)
            if time_until_next_step > 0:
                time.sleep(time_until_next_step)
        
        # Calculate elapsed time
        elapsed_time = time.time() - start
        
        # Print recording summary and cleanup
        if args.record:
            # Release video writer
            out.release()
            
            print(f"\n{'='*60}")
            print(f"Video recording complete!")
            print(f"  Frames recorded: {frame_count}")
            print(f"  Output file: {args.output_file}")
            print(f"  Simulation time: {elapsed_time:.2f}s / {simulation_duration}s (closed early)")
            print(f"  Video duration: {frame_count / intended_fps:.2f}s at {intended_fps:.1f} FPS")
            print(f"{'='*60}")
            print(f"\nThe video playback speed matches the simulation speed.")